{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports needed for the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Tkinter is Python's de-facto standard GUI (Graphical User Interface) package.\n",
    "import tkinter as tk\n",
    "import keras as kr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sklearn.preprocessing as pre\n",
    "import gzip\n",
    "import PIL\n",
    "from PIL import Image, ImageDraw\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the images for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by Importing the Images that we will use for training the model, then the images we will use to test the model and images used to identify the classes needed to identify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "     train_lbl = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "     test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "     test_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can create a sequential model, we can build it using layers to identify the dimentions to use. the tools to normalise the data, and which algorithm to use to optimise and train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a neural network, building it by layers.\n",
    "# using sequential model\n",
    "model = kr.models.Sequential()\n",
    "\n",
    "# Add a hidden layer with 1000 neurons and an input layer with 784.\n",
    "model.add(kr.layers.Dense(512, input_dim=784, activation=\"relu\", kernel_initializer=\"normal\"))\n",
    "model.add(kr.layers.Dense(10, activation=\"softmax\", kernel_initializer=\"normal\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape the mnist data set to match the conditions that we need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can reshape the inputs in or to train the network, using a list of images to train and a group of labels to identify the differnt classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the images and labels.\n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 1, 784).astype(np.uint8)\n",
    "train_lbl =  np.array(list(train_lbl[ 8:])).astype(np.uint8)\n",
    "\n",
    "train_img = train_img/ 255\n",
    "train_lbl = kr.utils.to_categorical(train_lbl)\n",
    "\n",
    "# reshape the image array\n",
    "inputs = train_img.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the Encoder so that we can use it to interpret the expected result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize labels in a one-vs-all fashion\n",
    "encoder = pre.LabelBinarizer()\n",
    "# Trains the model for a fixed number of epochs (iterations on a dataset).\n",
    "encoder.fit(train_lbl)\n",
    "outputs = encoder.transform(train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the nueral network by giving it a group of inputs and expected outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.5218 - acc: 0.8463\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.3155 - acc: 0.9063\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.2498 - acc: 0.9258 1s - loss: \n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.2001 - acc: 0.9397 \n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1677 - acc: 0.9501\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1475 - acc: 0.9560\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1359 - acc: 0.9588\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.1247 - acc: 0.9625\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1139 - acc: 0.9647 0s - loss: 0.1141 - acc: 0\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1052 - acc: 0.9675\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1014 - acc: 0.9684\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0936 - acc: 0.9709\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0881 - acc: 0.9723\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0867 - acc: 0.9726 5s - - ETA: 4\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.0813 - acc: 0.9741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ebcd7be5c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(inputs, outputs, epochs=15, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can save the model so that it can be read in again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the current model\n",
    "kr.models.save_model(\n",
    "    model,\n",
    "    \"model2.h5py\",\n",
    "    overwrite=True,\n",
    "    include_optimizer=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model from file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the model exists, we can load it so that the network wont have to be trained each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the model file exists load it\n",
    "if os.path.isfile('data/model2.h5py'): \n",
    "    model = kr.models.load_model('data/model2.h5py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read in an image to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets open the image we want to test, feel free to test without images by changing the relative paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in an image and greyscale\n",
    "im = Image.open('data/image.png').convert('L')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can show the image that we loaded and see the image using the default image viewer in the OS. It will show a black background with a white digit. This is loading the image saved by the project program \"digitrecognition.py\", so it can change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the data and reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must normalise the data so that the values are easier to read for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data from the image\n",
    "tv = list(im.getdata())\n",
    "\n",
    "# normalize pixels to 0 and 1. 0 is pure white, 1 is pure black.\n",
    "tv = [(255 - x) * 1.0 / 255.0 for x in tv]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We resize the image to an array of 1*784 so that it can be compared to the training data we have trained the network using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =  np.array(list(tv)).reshape(1,784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we can predict the class from the model we trained and get the response expected for the image we have input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the image in this case is an 8 and the image that I have tested is an 8."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
